{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HathiTrust US Federal Document Suggester Analysis\n",
    "### *Analysis of missing USFD in known USFDs using the HT US Fed Docs Registry*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "HathiTrust (HT) determines US Federal Documents (USFDs) through bibliographic analysis. Specifically, the 008 is inspected for a designation it was published in the US and is a federal document*. Many institutions have deposited USFDs in the HT repository but have yet to indicate them through the 008 in the MARC record. If they were to update their metdata records with the correct indicators, many of these volumes would be bibliographically determined to be public domain. This new determination would give the public access through the HT web site. \n",
    "\n",
    "We can identify many of these unmarked USFDs by using the HT US Federal Documents registry, which maintains a database of OCLC numbers of US Federal Documents. By cross-referencing this database with the OCLC numbers in Zephir's HT metadata database, we can find volumes which are not marked as a USFD, but probably should be. From this we can derive lists to give to contributors suggesting records to inspect and update if they truly are USFDs.\n",
    "\n",
    "This notebook analysis this overlap and creates a prototype for generating suggestion lists.\n",
    "\n",
    "*This is a proxy for US Federal Documents, as sometimes the US government publshes documents outside of the US and other countries may puplish documents in the US."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import collections\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zephir/USFD Registry Overlap\n",
    "This is a dataset of overlap between two data sources (Zephir and HT USFD Registry). It was created by [jupyter notebook](http://localhost:8888/lab/tree/create_overlap_dataset.ipynb) matching on exports from each source. OCLC was used as a matchpoint between the sources. Since hathitrust volumes can have more than one OCLC number, it is possible for a volume to be duplicated in this overlap dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/zephir-htusfd-overlap.manifest.json') as json_file:\n",
    "    overlap_manifest = json.load(json_file)\n",
    "    \n",
    "print(\"The {} was created on {}\".format(overlap_manifest[\"name\"], overlap_manifest[\"datetime\"]))\n",
    "print(\"The dataset was derived from:\")\n",
    "for dataset in overlap_manifest[\"data-origins\"]:\n",
    "    print(\"Dataset {} created at {}\".format(dataset[\"origin\"],dataset[\"datetime\"]))\n",
    "\n",
    "usfd_overlap_df = pandas.read_csv(\"data/zephir-htusfd-overlap.csv\", dtype=overlap_manifest[\"schema\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many volumes in HathiTrust have overlapping OCLCs in the US Fed Docs Registry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only count unique volumes, some may have multiple oclcs and matches\n",
    "volumes_matched = usfd_overlap_df.htid.unique()\n",
    "print(\"There are {} volumes w/ OCLC numbers matched in the registry\".format(len(volumes_matched)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of those volumes are not marked USFD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep records not marked as USFD\n",
    "usfd_suggest_df = usfd_overlap_df[usfd_overlap_df['usfd_status']==False]\n",
    "# Drop OCLC and eliminate duplicates caused by multiple OCLC matches\n",
    "unique_usfd_suggest_df = usfd_suggest_df.drop(columns=\"oclc\").drop_duplicates(keep=\"first\")\n",
    "print(\"There are {} volumes not marked USFD\".format(len(unique_usfd_suggest_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the breakdown of those volumes by contributor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Contributors by volumes\")\n",
    "print(unique_usfd_suggest_df[[\"contributor_code\", \"htid\"]].groupby([\"contributor_code\"]).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many bibliographic records submitted from ILS systems are not marked USFD? \n",
    "\n",
    "There can be multiple volulmes associated with a single bibliographic record, so this count will be lower. Ultimately, to update the 008, they contributor will need to us the ILS biblographic identifier rather than the HT volume identifier. We call this identifier the 'contribsys_id' in the Zephir database. They will then need to update that biblographic record in their ILS and resubmit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop HTID and eliminate duplicates from 1-N relationship with contribsys_id (Contributor's ILS Bib #)\n",
    "unique_contribsys_usfd_df = unique_usfd_suggest_df.drop(columns=[\"htid\"]).drop_duplicates(keep=\"first\")\n",
    "print(\"Total count by contribsys_id: {}\".format(len(unique_contribsys_usfd_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the contributor summary by bibliographic control identifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Contributors by contribsys_id (ILS Bib #)\")\n",
    "print(unique_contribsys_usfd_df[[\"contributor_code\", \"contribsys_id\"]].groupby([\"contributor_code\"]).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving dataset\n",
    "\n",
    "Export candidate suggestions to a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# presort the output\n",
    "sorted_contribsys_suggestions_df = unique_contribsys_usfd_df.sort_values(by=[\"contributor_code\", \"contribsys_id\"])\n",
    "export_df = unique_contribsys_usfd_df.drop(columns=\"usfd_status\")\n",
    "\n",
    "dataset_name = \"htusfd-suggestions\"\n",
    "dataset_file = \"data/{}.csv\".format(dataset_name)\n",
    "\n",
    "# save the dataset\n",
    "export_df.to_csv(\"data/{}.csv\".format(manifest[\"name\"]), header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a manifest\n",
    "manifest = {}\n",
    "manifest[\"name\"] = dataset_name\n",
    "manifest[\"description\"] = \"Dataset for identifying possible unmarked USFD by contributor\"\n",
    "manifest[\"datetime\"] = str(datetime.datetime.utcfromtimestamp(os.path.getmtime(\"data/{}.csv\".format(manifest[\"name\"]))).isoformat())\n",
    "\n",
    "# derive schema from dataframe\n",
    "schema = collections.OrderedDict()\n",
    "for column in export_df.columns.array:\n",
    "    schema[str(column)]= str(export_df.dtypes[column])\n",
    "manifest[\"schema\"] = schema\n",
    "\n",
    "# not format\n",
    "manifest[\"format\"] = {\n",
    "        \"delimiter\": \",\",\n",
    "        \"encoding\": \"utf8\",\n",
    "        \"extension\": \"csv\",\n",
    "        \"header\": True,\n",
    "        \"type\": \"delimited\"\n",
    "    }\n",
    "        \n",
    "# note the origins\n",
    "manifest[\"data-origins\"] = [{\n",
    "    \"origin\": \"zephir-htusfd-overlap.csv\",\n",
    "    \"datetime\": str(overlap_manifest[\"datetime\"])}]\n",
    "\n",
    "# save the manifest\n",
    "manifest_file = \"data/{}.manifest.json\".format(manifest[\"name\"])\n",
    "with open(manifest_file, 'w') as outfile:\n",
    "    json.dump(manifest, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finishing up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Completed notebook ({}).\".format(datetime.datetime.utcnow().isoformat()))\n",
    "print(\"Output created:\")\n",
    "print(dataset_file)\n",
    "print(manifest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
